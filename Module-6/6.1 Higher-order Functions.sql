{"version":"NotebookV1","origId":3623476344927262,"name":"6.1 Higher-order Functions","language":"sql","commands":[{"version":"CommandV1","origId":3623476344927263,"guid":"9e32e750-8d03-47df-be39-6e2f6cce29c3","subtype":"command","commandType":"auto","position":1.0,"command":"\n%md-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"81b20963-54a4-4aa4-9207-741dfb903431"},{"version":"CommandV1","origId":3623476344927264,"guid":"53a20980-e68e-4f0d-bf0b-1a53342c6046","subtype":"command","commandType":"auto","position":2.0,"command":"%md\n## Higher-order functions\n\nHigher order functions in Spark SQL allow you to work directly with complex data types. When working with hierarchical data, as we were in the previous lesson and lab, records are frequently stored as array or map type objects. This lesson will demonstrate how to use higher-order functions to transform, filter, and flag array data while preserving the original structure. In this notebook, we work strictly with arrays of strings; in the subsquent notebook, you will work with more functions and numerical data. Skilled application of these functions can make your work with this kind of data faster, more powerful, and more reliable. \n\nIn this notebook, you will: \n* Apply higher-order functions (`TRANSFORM`, `FILTER`, `EXISTS`) to arrays of strings \n\nRun the following queries to learn about how to work with higher-order functions.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"2c0b40cb-39df-4c47-a4cc-eeb9f833b5de"},{"version":"CommandV1","origId":3623476344927265,"guid":"67f5e75e-2276-463f-a1d0-a1f2f283115f","subtype":"command","commandType":"auto","position":3.0,"command":"%md\n## Getting Started\nRun the cell below to set up your classroom environment","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"8c6af32e-a869-461b-ba19-48473e0fbfde"},{"version":"CommandV1","origId":3623476344927266,"guid":"ce664bf3-46da-4c4a-b264-8dbc8c811297","subtype":"command","commandType":"auto","position":4.0,"command":"%run ../Includes/Classroom-Setup","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"a372ae20-c578-4f91-bc5d-dbf765cc76f7"},{"version":"CommandV1","origId":3623476344927267,"guid":"a5fc3122-18d6-4194-8758-4eb317b8adf7","subtype":"command","commandType":"auto","position":5.0,"command":"%md\n## Working with Text Data\n\nWe can use higher-order functions to easily work with arrays of text data. The exercises in this section are meant to demonstrate the `TRANSFORM`, `FILTER`, and `EXISTS` functions to manipulate data and create flags for when a value does or does not exist. \n\nThese examples use data collected about Databricks blog posts. Run the cell below to create the table. Then, run the next cell to view the schema. \n\nIn this data set, the `authors` and `categories` columns are both ArrayType; we'll be using these columns with higher-order functions. ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"b6d4bc68-fbf4-4f59-95d3-832a6a9c6a51"},{"version":"CommandV1","origId":3623476344927268,"guid":"6cbdf6f9-f7c7-41b7-b615-dabd9044ce26","subtype":"command","commandType":"auto","position":6.0,"command":"CREATE TABLE IF NOT EXISTS DatabricksBlog\n  USING json\n  OPTIONS (\n    path \"dbfs:/mnt/training/databricks-blog.json\",\n    inferSchema \"true\"\n  )","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"264ab40d-0e1b-4103-9a27-073206112ce0"},{"version":"CommandV1","origId":3623476344927269,"guid":"d9156b6e-a640-442c-ae4c-f1ffb5d7baf8","subtype":"command","commandType":"auto","position":7.0,"command":"DESCRIBE DatabricksBlog","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"fd12b0b9-28d8-4d86-a323-baa7e3fd01b8"},{"version":"CommandV1","origId":3623476344927270,"guid":"19a7ba25-1798-4260-ac57-dbd3a4b3b14b","subtype":"command","commandType":"auto","position":8.0,"command":"%md\n### Filter\n\n[Filter](https://spark.apache.org/docs/latest/api/sql/#filter) allows us to create a new column based on whether or not values in an array meet a certain condition. Let's say we want to remove the category `\"Engineering Blog\"` from all records in our `categories` column. I can use the `FILTER` function to create a new column that excludes that value from the each array. \n\nLet's dissect this line of code to better understand the function:\n\n`FILTER (categories, category -> category <> \"Engineering Blog\") woEngineering`\n\n**`FILTER`** : the name of the higher-order function <br>\n**`categories`** : the name of our input array <br>\n**`category`** : the name of the iterator variable. You choose this name and then use it in the lambda function. It iterates over the array, cycling each value into the function one at a time.<br>\n**`->`** :  Indicates the start of a function <br>\n**`category <> \"Engineering Blog\"`** : This is the function. Each value is checked to see if it **is different** than the value `\"Engineering Blog\"`. If it is, it gets filtered into the new column, `woEnginieering`","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"12c887d3-7166-4d54-b702-16842025c8db"},{"version":"CommandV1","origId":3623476344927271,"guid":"80a12550-fd5a-4aa9-b809-431a530f3d6d","subtype":"command","commandType":"auto","position":9.0,"command":"SELECT\n  categories,\n  FILTER (categories, category -> category <> \"Engineering Blog\") woEngineering\nFROM DatabricksBlog\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"0e5d3e7c-4a69-432c-8e96-0119c439cebf"},{"version":"CommandV1","origId":3623476344927272,"guid":"acaf5485-5de3-40d6-9ad2-2ba7ce3a3eee","subtype":"command","commandType":"auto","position":10.0,"command":"%md\n### Filter, subqueries, and `WHERE`\n\nYou may write a filter that produces a lot of empty arrays in the created column. When that happens, it can be useful to use a `WHERE` clause to show only non-empty array values in the returned column. \n\nIn this example, we accomplish that by using a subquery. A **subquery** in SQL is a query within a query. They are useful for performing an operations in multiple steps. In this case, we're using it to create the named column that we will use with a `WHERE` clause. ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"fd2b484d-4fe1-4e80-8e4b-f780118a995c"},{"version":"CommandV1","origId":3623476344927273,"guid":"13fd5992-0951-4365-bf98-90913cb8bb8a","subtype":"command","commandType":"auto","position":11.0,"command":"SELECT\n  *\nFROM\n  (\n    SELECT\n      authors, title,\n      FILTER(categories, category -> category = \"Engineering Blog\") AS blogType\n    FROM\n      DatabricksBlog\n  )\nWHERE\n  size(blogType) > 0","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"476337f4-d428-4e20-8991-96b6b3063ca4"},{"version":"CommandV1","origId":3623476344927274,"guid":"40896e69-c710-494c-b1b5-8f61052b3ee5","subtype":"command","commandType":"auto","position":12.0,"command":"%md\n\n### Exists\n\n[Exists](https://spark.apache.org/docs/latest/api/sql/#exists) tests whether a statement is true for one or more elements in an array. Let's say we want to flag all blog posts with `\"Company Blog\"` in the categories field. I can use the `EXISTS` function to mark which entries include that category.\n\nLet's dissect this line of code to better understand the function: \n\n`EXISTS (categories, c -> c = \"Company Blog\") companyFlag`\n\n**`EXISTS`** : the name of the higher-order function <br>\n**`categories`** : the name of our input array <br>\n**`c`** : the name of the iterator variable. You choose this name and then use it in the lambda function. It iterates over the array, cycling each value into the function one at a time. Note that we're using the same kind as references as in the previous command, but we name the iterator with a single letter<br>\n**`->`** :  Indicates the start of a function <br>\n**`c = \"Engineering Blog\"`** : This is the function. Each value is checked to see if it **is the same as** the value `\"Company Blog\"`. If it is, it gets flagged into the new column, `companyFlag`","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"7dbae0d6-6637-495b-9718-29493e064474"},{"version":"CommandV1","origId":3623476344927275,"guid":"910aa840-b2b6-47f6-99aa-f84053b17e72","subtype":"command","commandType":"auto","position":13.0,"command":"SELECT\n  categories,\n  EXISTS (categories, c -> c = \"Company Blog\") companyFlag\nFROM DatabricksBlog\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"02c26aa1-9c09-4825-89d2-3806fb639492"},{"version":"CommandV1","origId":3623476344927276,"guid":"1b5f7b2d-ab1d-4055-9828-6a766021bd47","subtype":"command","commandType":"auto","position":14.0,"command":"%md\n### Transform\n\n[Transform](https://spark.apache.org/docs/latest/api/sql/#transform) uses the provided function to transform all elements of an array. SQL's built-in functions are designed to operate on a single, simple data type within a cell. They cannot process array values. Transform can be particularly useful when you want to apply an existing function to each element in an array. In this case, we want to rewrite all of the names in the `categories` column in lowercase. \n\nLet's dissect this line of code to better understand the function: \n\n`TRANSFORM(categories, cat -> LOWER(cat)) lwrCategories`\n\n**`TRANSFORM`** : the name of the higher-order function <br>\n**`categories`** : the name of our input array <br>\n**`cat`** : the name of the iterator variable. You choose this name and then use it in the lambda function. It iterates over the array, cycling each value into the function one at a time. Note that we're using the same kind as references as in the previous command, but we name the iterator with a new variable<br>\n**`->`** :  Indicates the start of a function <br>\n**`LOWER(cat)`** : This is the function. For each value in the input array, the built-in function `LOWER()` is applied to transform the word to lowercase. ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"8136256f-92f5-477b-aa26-8994222801e9"},{"version":"CommandV1","origId":3623476344927277,"guid":"5ca67c60-65c9-463f-883d-fb057a4ed165","subtype":"command","commandType":"auto","position":15.0,"command":"SELECT \n  TRANSFORM(categories, cat -> LOWER(cat)) lwrCategories\nFROM DatabricksBlog","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"1dad9ea7-2923-4dba-9898-f7d021d74b12"},{"version":"CommandV1","origId":3623476344927278,"guid":"a90aec2e-e25f-4a02-a0cc-af278da3acf1","subtype":"command","commandType":"auto","position":16.0,"command":"%run ../Includes/Classroom-Cleanup\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"7be68242-347b-49eb-8272-a218620eb4a3"},{"version":"CommandV1","origId":3623476344927279,"guid":"511c077d-e963-44e1-ad9f-3a7cb74af02f","subtype":"command","commandType":"auto","position":17.0,"command":"%md-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"useConsistentColors":false,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","latestUserId":null,"commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"isLockedInExamMode":false,"iPythonMetadata":null,"streamStates":{},"datasetPreviewNameToCmdIdMap":{},"nuid":"05543a5d-103b-4d32-b1e4-a90ca3078264"}],"dashboards":[],"guid":"51226485-6737-46a6-a744-a9af835124b0","globalVars":{},"iPythonMetadata":null,"inputWidgets":{},"notebookMetadata":{"pythonIndentUnit":2}}